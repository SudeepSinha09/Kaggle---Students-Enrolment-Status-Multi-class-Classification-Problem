# -*- coding: utf-8 -*-
"""[Detailed] Kaggle - Students Enrolment Status Multi-class Classification Problem.ipynb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1v4OTCfI97OJL_kXreHI5Qnc7FSNQZFcd
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

"""# Student Enrolment Status
`Multi-Class classification Problem`

## STEP 1 : Look at the big picture

This is a supervised learning problem that involves multi-class classification. The objective is to classify students into one of three categories: dropout, enrolled, or graduate, based on their status at the end of the normal duration of the course. The dataset assigns numerical codes 0, 1, and 2 to represent each class.

## STEP 2 : Get the data
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df_train = pd.read_csv("/content/Train-Kaggle-Students_Enrolment_Status.csv")
df_test = pd.read_csv("/content/Test-Kaggle-Students_Enrolment_Status.csv")

#df_train = pd.read_csv("../input/students-drop-out-prediction/train.csv")
#df_test = pd.read_csv("../input/students-drop-out-prediction/test.csv")

"""### Check data samples"""

df_train.head()

df_test.head()

print(df_train.shape, df_test.shape)

"""### Features

#### train data
"""

df_train = df_train.drop(columns='id', axis=1)
df_train

"""#### test data"""

df_test_copy = df_test.copy()
df_test_copy = df_test_copy.drop(columns='id', axis=1)
df_test_copy

df_train.shape, df_test.shape

feature_names = df_train.columns[:-1].values
label = [df_train.columns[-1]]

print("Feature names: ", feature_names)
print("Label: ", label)

df_train

"""### Data statistics"""

df_train.info()

df_train.describe()

df_train['label'].value_counts()

sns.set()
df_train.label.hist()
plt.xlabel('label')
plt.ylabel('Count')

"""## STEP 3 : Data Visualization"""

exploration_set = df_train.copy()

"""### Scatter Visualization"""

#sns.scatterplot(hue='label', data=exploration_set)

"""### Correlation matrix"""

# corr funcn to calculate correlation
corr_matrix = exploration_set.corr()

corr_matrix

corr_matrix['label']

"""#### Correlation matrix with heatmap"""

plt.figure(figsize=(40, 40))
sns.heatmap(corr_matrix, annot=True);

"""## STEP 4 : Prepare the data for ML algo

### Separate features and labels form the training set
"""

# copying all features leaving aside the label.
enroll_features = df_train.drop("label", axis=1)

# copy the label list
enroll_labels = df_train['label']

"""### Separate features and labels from strat test set"""

test_enroll_features = df_test_copy

test_enroll_features.shape

"""### Data Cleaning"""

'''Counts the no. of NaN in each column of wine_feature'''
enroll_features.isna().sum()

"""Since, not any features have missing values, so we are not going to take help of imputer """

enroll_features.median()

"""### Data Preprocessing"""

from sklearn.preprocessing import MinMaxScaler,\
    StandardScaler, MaxAbsScaler, LabelBinarizer
from sklearn.pipeline import Pipeline

enroll_features = StandardScaler().fit_transform(enroll_features)

test_enroll_features = StandardScaler().fit_transform(test_enroll_features)

enroll_features

test_enroll_features

# enroll_labels = LabelBinarizer().fit_transform(enroll_labels)

# enroll_labels

# test_enroll_features=StandardScaler.fit_transform(test_enroll_features)

"""## STEP 5 : Selection and training of ML models """

''' Imports '''
#Visualizing the confusion matrix

from sklearn.metrics import ConfusionMatrixDisplay,\
   confusion_matrix, precision_recall_curve,\
   precision_score, recall_score,\
   classification_report, make_scorer

from sklearn.model_selection import cross_validate,\
  cross_val_predict, GridSearchCV, cross_val_score

"""Polynomial regression/Logistic regression with cross validation.

### Baseline Model 
A baseline model is essentially a simple model that acts as a reference in a machine learning project. Its main function is to contextualize the results of trained models.

Baseline models usually lack complexity and may have little predictive power. Regardless, their inclusion is a necessity for many reasons.

There is a very strong case for building baseline models prior to any other model.

Baseline models are not only very easy to build, but they also provide a lot of information that can dictate the future steps in a machine learning project.

### Logistic Regression Model
"""

# '''Imports'''
# from sklearn.linear_model import LogisticRegression

# np.random.seed(42)

# lr=LogisticRegression(random_state=1729,multi_class='multinomial')
# lr.fit(enroll_features, enroll_labels)
# lr.score(enroll_features, enroll_labels)

# pred_enroll_labels = lr.predict(enroll_features)

# '''Confusion matrix'''
# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

# acc = cross_val_score(estimator=lr, X=enroll_features, y=enroll_labels, cv=10)
# print(type(acc))
# print('Accuracy of each fold ', list(acc*100))
# print('Accuracy: {:.2f} %'.format(acc.mean()*100))

"""### Perceptron"""

# '''Imports'''


# from sklearn.linear_model import Perceptron

# from sklearn.metrics import ConfusionMatrixDisplay,\
#    confusion_matrix, precision_recall_curve,\
#    precision_score, recall_score,\
#    classification_report, make_scorer

# from sklearn.model_selection import cross_validate,\
#   cross_val_predict, GridSearchCV

# percep = Perceptron(random_state = 1729)

# percep.fit(enroll_features, enroll_labels)
# percep.score(enroll_features, enroll_labels)

# pred_enroll_labels = percep.predict(enroll_features)

'''Confusion matrix'''
# ConfusionMatrixDisplay.from_predictions(enroll_labels, pred_enroll_labels);

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

# from sklearn.model_selection import cross_val_score
# acc = cross_val_score(estimator=percep, X=enroll_features, y=enroll_labels, cv=10)
# print(type(acc))
# print('Accuracy of each fold ', list(acc*100))
# print('Accuracy: {:.2f} %'.format(acc.mean()*100))

"""### DecisionTreeClassifier"""

# from sklearn.tree import DecisionTreeClassifier

# DTC = DecisionTreeClassifier(max_depth=3, random_state=42)

# DTC.fit(enroll_features, enroll_labels)

# print("model score: %.3f" % DTC.score(enroll_features, enroll_labels))

# pred_enroll_labels = DTC.predict(enroll_features)

# '''Confusion matrix'''
# ConfusionMatrixDisplay.from_predictions(enroll_labels, pred_enroll_labels)

# print(classification_report(enroll_labels, pred_enroll_labels))

# from sklearn.model_selection import cross_val_score
# acc = cross_val_score(estimator=DTC, X=enroll_features, y=enroll_labels, cv=10)
# print(type(acc))
# print('Accuracy of each fold ', list(acc*100))
# print('Accuracy: {:.2f} %'.format(acc.mean()*100))

"""### KNN"""

# '''Imports'''
# from sklearn.neighbors import KNeighborsClassifier

# np.random.seed(42)
# knn = GridSearchCV(KNeighborsClassifier(algorithm='auto'),\
#                    {'n_neighbors':[2,4,5],\
#                     'weights':['uniform', 'distance'],\
#                    'metric':['euclidean', 'manhattan']},cv=5)
# knn.fit(enroll_features, enroll_labels)
# knn.score(enroll_features, enroll_labels)

# tuned_knn = KNeighborsClassifier(n_neighbors=3)

# tuned_knn.fit(enroll_features, enroll_labels)

# print("Model score: %.3f" % tuned_knn.score(enroll_features, enroll_labels))

# pred_enroll_labels = tuned_knn.predict(enroll_features)

# tuned_knn.classes_

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""### SVM"""

# '''Imports'''
# from sklearn.svm import SVC
# np.random.seed(42)
# GS=GridSearchCV(SVC(), {'kernel':['linear', 'rbf'],\
#                         'C':[0.1, 1, 30]},cv=10)
# GS.fit(enroll_features, enroll_labels)
# GS.best_params_

# from sklearn.svm import SVC
# np.random.seed(42)

# tuned_svc=SVC(C=1, kernel='rbf')
# tuned_svc.fit(enroll_features, enroll_labels)
# tuned_svc.score(enroll_features, enroll_labels)

# tuned_svc30=SVC(C=30, kernel='rbf')
# tuned_svc30.fit(enroll_features, enroll_labels)
# tuned_svc30.score(enroll_features, enroll_labels)

# pred_enroll_labels = tuned_svc.predict(test_enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""### Random Forest"""

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score
rfc = RandomForestClassifier(n_estimators=100)
rfc.fit(enroll_features, enroll_labels)
rfc.score(enroll_features, enroll_labels)
# scores = cross_val_score(rfc_cv, enroll_features, enroll_labels, cv=10, scoring = "accuracy")
# print("Scores:", scores)
# print("Mean:", scores.mean())
# print("Standard Deviation:", scores.std())

"""#### Hyperparameter tuning"""

# from sklearn.model_selection import RandomizedSearchCV
# # Number of trees in random forest
# n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
# # Number of features to consider at every split
# max_features = ['auto', 'sqrt']
# # Maximum number of levels in tree
# max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
# max_depth.append(None)
# # Minimum number of samples required to split a node
# min_samples_split = [2, 5, 10]
# # Minimum number of samples required at each leaf node
# min_samples_leaf = [1, 2, 4]
# # Method of selecting samples for training each tree
# bootstrap = [True, False]

# # Create the random grid
# random_grid = {'n_estimators': n_estimators,
#                'max_features': max_features,
#                'max_depth': max_depth,
#                'min_samples_split': min_samples_split,
#                'min_samples_leaf': min_samples_leaf,
#                'bootstrap': bootstrap}

# # Use the random grid to search for best hyperparameters
# # First create the base model to tune
# rf = RandomForestClassifier()
# # Random search of parameters, using 3 fold cross validation, 
# # search across 100 different combinations, and use all available cores
# rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)
# # Fit the random search model
# rf_random.fit(enroll_features, enroll_labels)

# rf_random.best_params_

tuned_rfc = RandomForestClassifier(n_estimators=800,
                             min_samples_split=5,
                             min_samples_leaf= 4,
                             max_features='sqrt',
                             max_depth=30,
                             bootstrap=False, random_state=42)
tuned_rfc.fit(enroll_features, enroll_labels)

tuned_rfc.score(enroll_features, enroll_labels)

pred_enroll_labels = tuned_rfc.predict(enroll_features)

cm = confusion_matrix(enroll_labels, pred_enroll_labels)
disp = ConfusionMatrixDisplay(cm)
disp.plot()
plt.plot('Confusion matrix');

print(classification_report(enroll_labels, pred_enroll_labels))

"""### Bagging"""

# '''Imports'''
# from sklearn.ensemble import BaggingClassifier, RandomForestClassifier

# bc=BaggingClassifier(base_estimator=RandomForestClassifier())
# bc.fit(enroll_features, enroll_labels)
# bc.score(enroll_features, enroll_labels)

# pred_enroll_labels = bc.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""### Boosting"""

# '''Imports'''
# from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
# abc=AdaBoostClassifier(n_estimators=50,\
#         base_estimator=RandomForestClassifier())
# abc.fit(enroll_features, enroll_labels)
# abc.score(enroll_features, enroll_labels)

# pred_enroll_labels = abc.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

# '''RFECV'''
# from sklearn.feature_selection import RFECV

# rfecv_abc = RFECV(abc, importance_getter='feature_importances_',\
#                   step=1, cv=5)
# rfecv_abc.fit(enroll_features, enroll_labels)
# rfecv_abc.score(enroll_features, enroll_labels)

# '''Sequential Feature Selector'''
# from sklearn.feature_selection import SequentialFeatureSelector

# sfs_abc = SequentialFeatureSelector(abc, n_features_to_select=5)
# sfs_abc.fit_transform(enroll_features, enroll_labels)
# sfs_abc.get_support()

# sfs_abc.score(enroll_features, enroll_labels)

"""#### Hyperparameter tuning"""

# '''Imports'''
# from sklearn.model_selection import RepeatedStratifiedKFold
# '''Hyperparameters Grid Search'''
# # define the grid of values to search
# grid = dict()
# grid['n_estimators'] = [10, 50, 100, 500]
# grid['learning_rate'] = [0.0001, 0.001, 0.01, 0.1, 1.0]

# # define the evaluation procedure
# cv=RepeatedStratifiedKFold(n_splits=10,\
#                            n_repeats=3, random_state=1)

# # define the grid search procedure
# grid_search = GridSearchCV(estimator=abc, param_grid=grid,
#                 n_jobs=-1, cv=cv, scoring='accuracy')

# # execute the grid search
# tuned_abc = grid_search.fit(enroll_features, enroll_labels) 

# # summarize the best score and configuration
# print("Best: %f using %s" % (tuned_abc.best_score_,\
#             tuned_abc.best_params_))

# # summarize all scores that were evaluated
# means = tuned_abc.cv_results_['mean_test_score']
# stds = tuned_abc.cv_results_['std_test_score']
# params = tuned_abc.cv_results_['params']
# for mean, stdev, param in zip(means, stds, params):
#     print("%f (%f) with: %r" % (mean, stdev, param))

# pred_enroll_labels = tuned_abc.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

# '''RFECV'''
# from sklearn.feature_selection import RFECV

# rfecv_abc = RFECV(tuned_abc, step=1, cv=5)
# rfecv_abc.fit(enroll_features, enroll_labels)
# rfecv_abc.score(enroll_features, enroll_labels)

# pred_enroll_labels = rfecv_abc.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""### XGB"""

# '''Imports'''
# import xgboost as xgb

# xgbc = xgb.XGBClassifier()
# xgbc.fit(enroll_features, enroll_labels)
# xgbc.score(enroll_features, enroll_labels)

# pred_enroll_labels = xgbc.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""#### hyperparameter tuning"""

# # np.random.seed(42)

# tuned_xgb = GridSearchCV(xgbc,\
# {"learning_rate"    : [0.05,0.15,0.30 ] ,
#  "max_depth"        : [ 3, 4, 5, 6, 8, 10, 12, 15],
#  "min_child_weight" : [ 1, 3, 5, 7 ],
#  "gamma"            : [ 0.0, 0.1, 0.2 , 0.3, 0.4 ],
#  "colsample_bytree" : [ 0.3, 0.4, 0.5 , 0.7 ] },cv=5)
# tuned_xgb.fit(enroll_features, enroll_labels)
# tuned_xgb.score(enroll_features, enroll_labels)

# xgb_cv = xgb.XGBClassifier(n_estimators=100)
# scores = cross_val_score(xgb_cv, enroll_features, enroll_labels, cv=10, scoring = "accuracy")
# print("Scores:", scores)
# print("Mean:", scores.mean())
# print("Standard Deviation:", scores.std())

# pred_enroll_labels = xgb_cv.predict(enroll_features)

# cm = confusion_matrix(enroll_labels, pred_enroll_labels)
# disp = ConfusionMatrixDisplay(cm)
# disp.plot()
# plt.plot('Confusion matrix');

# print(classification_report(enroll_labels, pred_enroll_labels))

"""## Sample submission"""

# test_enroll_labels=abc.predict(df_test)
# output=pd.DataFrame({'id':df_test.id, 'label':test_enroll_labels})
# output.to_csv('submission.csv', index=False)
# print("Your submission was successfully saved!")

test_enroll_labels = tuned_rfc.predict(test_enroll_features)
df_test['label']=test_enroll_labels
col1=df_test['id'].to_numpy()
col2=df_test['label'].to_numpy()
df=np.column_stack((col1, col2))
pd.DataFrame(df, columns=['id', 'label']).to_csv('submission.csv',index=False)
print('successful')